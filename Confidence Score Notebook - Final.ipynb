{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec1b37c5",
   "metadata": {},
   "source": [
    "# CONFIDENCE SCORE OF LISTINGS IN OUR DATABASE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a5b827",
   "metadata": {},
   "source": [
    "* **Confidence Score** - This is a measure of how alive a listing is based on the properties we have in our database. \n",
    "\n",
    "\n",
    "* The **objective** of this project is to calculate and predict the **confidence score (range between 0 and 1)** of new listings posted in our database. \n",
    "\n",
    "\n",
    "* Some of the **main metrics** that can inform us of how alive a listing is are the following fields :\n",
    "\n",
    "    1. Social Media Presence i.e. Instagram, Facebook, LinkedIn, Twitter\n",
    "    2. Domain of email i.e. Yahoo, Gmail, Hotmail\n",
    "    3. Type of Phone i.e. Landline, Mobile, VOIP etc\n",
    "    4. Presence of website and its status i.e. active or inactive\n",
    "    5. Last Website Activity i.e. Last Modified/Refreshed, Last Updated, Age of the site etc. \n",
    "    6. Data Source i.e. Yellow Pages, Scrapped profiles, Business Lists etc.\n",
    "    7. Category of Listing i.e. Finance, Accomodation, Retail, Insurance, Healthcare etc\n",
    "    8. Health Score i.e. fullness/completeness of a profile\n",
    "    \n",
    "\n",
    "* The **major assumptions** we are working with for this task include :\n",
    "    1. Listings using a contact detail (*mobile number/email address*) have a higher probability of being alive\n",
    "    2. Listings with a more complete profile(*higher health score*) have a higher probability of being alive\n",
    "    3. Listings scraped from Yellow Pages are more likely to be alive than listings scraped from business lists\n",
    "    4. Listings with an ISP provider e.g. Safaricom, Airtel, MTN have a higher probability of being alive\n",
    "    5. Listings from Kenya, Ethiopia, South Africa, Ghana, Nigeria etc have a higher probability of being alive as a result of easy verification/reachability. \n",
    "    \n",
    "    \n",
    "* Some of the **biases** we are working with in this project include :\n",
    "    1. Majority of the listings in our database are from countries like Ethiopia, South Africa, Kenya, Nigeria and Ghana. \n",
    "    2. Majority of the listings in our dataset are in the *General Merchants* category.\n",
    "    \n",
    "    \n",
    "* We are going to use **unsupervised machine learning** in this project due to the fact that there is **no ground truth** as to whether a listing is alive or not when compiling them from a data source. The only way we can tell whether a listing is alive or not is by verifying using our call centre team thus the listing property *is_verified* in our database. \n",
    "\n",
    "\n",
    "* Why not use a **Supervised Machine Learning** algorithm ? This is because using the **is_verified** field as our target variable will not be accurate since majority of the listings in our database are yet to be verified in the first place (0 - 'pending verification', 1 - 'verified', 2 - 'rejected'). \n",
    "\n",
    "\n",
    "* **Suggestion** : In the near future, we can purpose to verify existing listings much faster so that we can use the **is_verified** field as a reference point (target variable) with the purpose of predicting the confidence score of new listings being added to the database. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758f9ad9",
   "metadata": {},
   "source": [
    "## Importing the necessary libraries into our environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "79fac028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import pairwise_distances, silhouette_score, calinski_harabasz_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca771723",
   "metadata": {},
   "source": [
    "## Reading the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915bf22c",
   "metadata": {},
   "source": [
    "We start by compiling all the train data sets from the database and concatenating them into one file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6cffd515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat all the files into one (Training Files)\n",
    "csv_files = [r\"C:\\Users\\derek\\Downloads\\training_data(1).csv\", r\"C:\\Users\\derek\\Downloads\\training_data(2).csv\", r\"C:\\Users\\derek\\Downloads\\training_data(3).csv\", r\"C:\\Users\\derek\\Downloads\\training_data(4).csv\", r\"C:\\Users\\derek\\Downloads\\training_data(5).csv\", r\"C:\\Users\\derek\\Downloads\\training_data(6).csv\", r\"C:\\Users\\derek\\Downloads\\training_data(7).csv\", r\"C:\\Users\\derek\\Downloads\\training_data(8).csv\", r\"C:\\Users\\derek\\Downloads\\training_data(9).csv\",r\"C:\\Users\\derek\\Downloads\\training_data(10).csv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084bb30f",
   "metadata": {},
   "source": [
    "The cell below is where we will be posting the datasets containing new listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6ab6681d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c.company_id</th>\n",
       "      <th>c.company_name_en</th>\n",
       "      <th>c.country</th>\n",
       "      <th>c.category_list</th>\n",
       "      <th>c.email</th>\n",
       "      <th>c.mobile</th>\n",
       "      <th>c.landline</th>\n",
       "      <th>c.isp_provider</th>\n",
       "      <th>c.geocode</th>\n",
       "      <th>c.has_contact_number</th>\n",
       "      <th>...</th>\n",
       "      <th>c.website</th>\n",
       "      <th>c.website_status</th>\n",
       "      <th>c.data_source</th>\n",
       "      <th>c.building_name</th>\n",
       "      <th>c.hours</th>\n",
       "      <th>c.confidence_indicator</th>\n",
       "      <th>c.latitude</th>\n",
       "      <th>c.longitude</th>\n",
       "      <th>c.is_headquarter</th>\n",
       "      <th>c.is_verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"ec94955a-5258-4517-bc3a-0225c68455a7\"</td>\n",
       "      <td>\"Cobra Knight Security\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"business_list\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"0516fad3-d072-4a9f-bb81-d23dbb8f8575\"</td>\n",
       "      <td>\"Medhaniyalem\"</td>\n",
       "      <td>\"Ethiopia\"</td>\n",
       "      <td>\"Clinics,Health Care/Personal Care and Social ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"+251918774047\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Ethio Telecom\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"263f2a48-6138-43ff-b459-ce95c9e72de3\"</td>\n",
       "      <td>\"Vertigo\"</td>\n",
       "      <td>\"South Africa\"</td>\n",
       "      <td>\"Retail Trade,Clothing-Retail\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[\"https://vertigoclothing.co.za\"]</td>\n",
       "      <td>\"inactive\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-26.111350</td>\n",
       "      <td>28.05282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"db1abf63-96de-4f58-a3fa-865351dd063d\"</td>\n",
       "      <td>\"Securec Air Condition Repairs and Installations\"</td>\n",
       "      <td>\"South Africa\"</td>\n",
       "      <td>\"Air Conditioning Equipment &amp; Systems-Repairing\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"+27824744471\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Vodacom\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"GMB\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"['1-7:00:00-24:00']\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-26.097207</td>\n",
       "      <td>28.03859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"0b639719-4b07-413e-9b46-1495ff7a058e\"</td>\n",
       "      <td>\"Kemila Kedir Abdo\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"+251906307251\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Ethio Telecom\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Ministry of Trade Ethiopia\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             c.company_id  \\\n",
       "0  \"ec94955a-5258-4517-bc3a-0225c68455a7\"   \n",
       "1  \"0516fad3-d072-4a9f-bb81-d23dbb8f8575\"   \n",
       "2  \"263f2a48-6138-43ff-b459-ce95c9e72de3\"   \n",
       "3  \"db1abf63-96de-4f58-a3fa-865351dd063d\"   \n",
       "4  \"0b639719-4b07-413e-9b46-1495ff7a058e\"   \n",
       "\n",
       "                                   c.company_name_en       c.country  \\\n",
       "0                            \"Cobra Knight Security\"             NaN   \n",
       "1                                     \"Medhaniyalem\"      \"Ethiopia\"   \n",
       "2                                          \"Vertigo\"  \"South Africa\"   \n",
       "3  \"Securec Air Condition Repairs and Installations\"  \"South Africa\"   \n",
       "4                                \"Kemila Kedir Abdo\"             NaN   \n",
       "\n",
       "                                     c.category_list c.email  \\\n",
       "0                                                NaN     NaN   \n",
       "1  \"Clinics,Health Care/Personal Care and Social ...     NaN   \n",
       "2                     \"Retail Trade,Clothing-Retail\"     NaN   \n",
       "3   \"Air Conditioning Equipment & Systems-Repairing\"     NaN   \n",
       "4                                                NaN     NaN   \n",
       "\n",
       "            c.mobile c.landline     c.isp_provider  c.geocode  \\\n",
       "0                NaN        NaN                NaN        NaN   \n",
       "1  [\"+251918774047\"]        NaN  [\"Ethio Telecom\"]        NaN   \n",
       "2                NaN        NaN                NaN        NaN   \n",
       "3   [\"+27824744471\"]        NaN        [\"Vodacom\"]        NaN   \n",
       "4  [\"+251906307251\"]        NaN  [\"Ethio Telecom\"]        NaN   \n",
       "\n",
       "   c.has_contact_number  ...                          c.website  \\\n",
       "0                   NaN  ...                                NaN   \n",
       "1                   1.0  ...                                NaN   \n",
       "2                   NaN  ...  [\"https://vertigoclothing.co.za\"]   \n",
       "3                   1.0  ...                                NaN   \n",
       "4                   1.0  ...                                NaN   \n",
       "\n",
       "  c.website_status                 c.data_source c.building_name  \\\n",
       "0              NaN               \"business_list\"             NaN   \n",
       "1              NaN                           NaN             NaN   \n",
       "2       \"inactive\"                           NaN             NaN   \n",
       "3              NaN                         \"GMB\"             NaN   \n",
       "4              NaN  \"Ministry of Trade Ethiopia\"             NaN   \n",
       "\n",
       "                 c.hours c.confidence_indicator  c.latitude  c.longitude  \\\n",
       "0                    NaN                    NaN         NaN          NaN   \n",
       "1                    NaN                 0.8677         NaN          NaN   \n",
       "2                    NaN                    NaN  -26.111350     28.05282   \n",
       "3  \"['1-7:00:00-24:00']\"                    NaN  -26.097207     28.03859   \n",
       "4                    NaN                    NaN         NaN          NaN   \n",
       "\n",
       "   c.is_headquarter  c.is_verified  \n",
       "0               NaN              1  \n",
       "1               0.0              0  \n",
       "2               0.0              0  \n",
       "3               NaN              0  \n",
       "4               NaN              0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the files and preview the dataset\n",
    "# csv_files = []\n",
    "training_data = pd.concat([pd.read_csv(file) for file in csv_files ], ignore_index=True)\n",
    "print(training_data.shape)\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "93bf4a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 21)\n"
     ]
    }
   ],
   "source": [
    "# Lets create a dataset that will contain the original dataset which we will use to retrieve the company names using the index. \n",
    "final = training_data\n",
    "print(final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219c5912",
   "metadata": {},
   "source": [
    "# Data Understanding\n",
    "\n",
    "* Some of the columns we have in our dataset include : \n",
    "    \n",
    "    1. **Company Name** - name of the listing\n",
    "    2. **Country / Region / location** - location of the listing\n",
    "    3. **Email Adress** - email address of the listing\n",
    "    4. **Mobile / Landline** - contact details of the listing\n",
    "    5. **ISP Provider** - internet service provider of the listings\n",
    "    6. **Website, Website Status** - presence/name of the website as well as its status i.e. active or inactive\n",
    "    7. **Category List** - category of the listing\n",
    "    8. **Health Score** - completeness/fullness of a listing's profile\n",
    "    9. **Has Contact Number** i.e 1 or null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a92b420",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb19e6e9",
   "metadata": {},
   "source": [
    "**1. First step is to deal with duplicates in our dataset. We drop them so as to maintain integrity in our data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "965202c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42611"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "training_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4c3f346a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39623, 21)\n"
     ]
    }
   ],
   "source": [
    "# We can view the duplicate listings before dropping them and keeping the first one.\n",
    "dups = training_data[training_data.duplicated(keep=False)]\n",
    "dups.sort_values(by=['c.company_name_en'], ascending=True)\n",
    "dups.to_clipboard()\n",
    "\n",
    "# Keep the first duplicate based on the company name, phone, email and country\n",
    "columns = ['c.company_name_en','c.category_list','c.country','c.email','c.mobile','c.landline','c.has_contact_number'] # Location_list, geocodes, \n",
    "dups = dups.drop_duplicates(subset = columns, keep='first')\n",
    "print(dups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "18b4d770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(880167, 21)\n"
     ]
    }
   ],
   "source": [
    "# Drop the duplicated records from the original dataset\n",
    "training_data = training_data.drop_duplicates(subset = columns, keep='first')\n",
    "print(training_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409958a3",
   "metadata": {},
   "source": [
    "**2. We then deal with null values in our columns. In this case we can impute the nulls with 0 for purposes of analysis and modelling.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "630b28b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 880167 entries, 0 to 999999\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   c.company_id            797582 non-null  object \n",
      " 1   c.company_name_en       880163 non-null  object \n",
      " 2   c.country               505235 non-null  object \n",
      " 3   c.category_list         416985 non-null  object \n",
      " 4   c.email                 112105 non-null  object \n",
      " 5   c.mobile                429531 non-null  object \n",
      " 6   c.landline              104204 non-null  object \n",
      " 7   c.isp_provider          416382 non-null  object \n",
      " 8   c.geocode               0 non-null       float64\n",
      " 9   c.has_contact_number    525774 non-null  float64\n",
      " 10  c.health_score          796258 non-null  float64\n",
      " 11  c.website               165274 non-null  object \n",
      " 12  c.website_status        125748 non-null  object \n",
      " 13  c.data_source           455775 non-null  object \n",
      " 14  c.building_name         20113 non-null   object \n",
      " 15  c.hours                 347934 non-null  object \n",
      " 16  c.confidence_indicator  434082 non-null  float64\n",
      " 17  c.latitude              331689 non-null  float64\n",
      " 18  c.longitude             331689 non-null  float64\n",
      " 19  c.is_headquarter        436857 non-null  float64\n",
      " 20  c.is_verified           880167 non-null  int64  \n",
      "dtypes: float64(7), int64(1), object(13)\n",
      "memory usage: 147.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# We can view the distribution of null values as well as data types of columns in our dataset\n",
    "training_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f7d6ddcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\derek\\AppData\\Local\\Temp\\ipykernel_7688\\952569595.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  training_data.drop(['c.geocode', 'c.company_id', 'c.is_headquarter'], axis=1, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "# We can drop the columns with the highest percentage of null values as well as unnecessary fields\n",
    "training_data.drop(['c.geocode', 'c.company_id', 'c.is_headquarter'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d6e7de",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f3412d",
   "metadata": {},
   "source": [
    "Considering that most variables in our dataset are categorical, we can go ahead and display their distribution in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d9dcd98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    754547\n",
      "1    125584\n",
      "2        36\n",
      "Name: c.is_verified, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verified \n",
    "print(training_data['c.is_verified'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a656580d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"inactive\"    81134\n",
       "\"active\"      44614\n",
       "Name: c.website_status, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Website Status\n",
    "training_data['c.website_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e56738e",
   "metadata": {},
   "source": [
    "Here we are attempting to find the websites last activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5270f31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# training_data['c.website'] = re.sub(\"[^a-zA-Z0-9]\",\"\", training_data['c.website'])\n",
    "# training_data['c.website']\n",
    "# training_data['c.domain'] = training_data['c.website'].apply(lambda x: urllib.parse.urlparse(x).netloc)\n",
    "\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import re\n",
    "# url = \"https://woodstockcycleworks.com\"\n",
    "# domain = 'youtube.com' \n",
    "# r = requests.post(url, {'domains': domain, 'submit': 'submit'})\n",
    "# soup = BeautifulSoup(r.content)\n",
    "# for item in soup.find_all('a', href=re.compile('website-history')):\n",
    "#     print(item.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c3982666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    525774\n",
       "Name: c.has_contact_number, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Has contact number\n",
    "training_data['c.has_contact_number'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5e469700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"General Merchants\"                                          20462\n",
       "\"Agriculture, Forestry, Fishing and Hunting,Animal Feeds\"     5364\n",
       "\"Animal Feeds,Agriculture, Forestry, Fishing and Hunting\"     5326\n",
       "\"Business,Retail Trade\"                                       4777\n",
       "\"Warehouses\"                                                  4774\n",
       "\"Retail Trade,Business\"                                       4717\n",
       "\"Schools - Primary\"                                           4711\n",
       "\"Importers,Transportation/Auto and Warehousing\"               4052\n",
       "\"Transportation/Auto and Warehousing,Importers\"               4040\n",
       "\"Shopping\"                                                    3536\n",
       "\"Schools - Primary,Educational Services\"                      3465\n",
       "\"Accommodation\"                                               3429\n",
       "\"Educational Services,Schools - Primary\"                      3403\n",
       "\"School Transport\"                                            3357\n",
       "\"Retail Trade,General Merchants\"                              3260\n",
       "\"General Merchants,Retail Trade\"                              3126\n",
       "\"Transport\"                                                   3053\n",
       "\"Retail Trade,Retail Shops\"                                   2992\n",
       "\"Retail Shops,Retail Trade\"                                   2969\n",
       "\"Accommodation and Food Services,Restaurants\"                 2782\n",
       "Name: c.category_list, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 20 Categories in our dataset\n",
    "print(training_data['c.category_list'].nunique())\n",
    "training_data['c.category_list'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6bbdada5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nigeria\"         142498\n",
       "\"South Africa\"    139816\n",
       "\"Ethiopia\"         52819\n",
       "\"Kenya\"            49263\n",
       "\"Uganda\"           18600\n",
       "\"Zambia\"           17556\n",
       "\"Mozambique\"       15766\n",
       "\"Zimbabwe\"         13414\n",
       "\"Saudi Arabia\"     10815\n",
       "\"Botswana\"         10124\n",
       "\"Namibia\"           9509\n",
       "\"Ghana\"             7510\n",
       "\"Malawi\"            5385\n",
       "\"Tanzania\"          4572\n",
       "\"Lesotho\"           2330\n",
       "\"Angola\"            1687\n",
       "\"Swaziland\"         1602\n",
       "\"Togo\"               908\n",
       "\"Ivory Coast\"        306\n",
       "\"Benin\"              165\n",
       "Name: c.country, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 20 Countries represented in our dataset\n",
    "training_data['c.country'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be85c12",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981ad347",
   "metadata": {},
   "source": [
    "**First, we create new columns that will give us additional information based on the columns in our dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ccb337f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\derek\\AppData\\Local\\Temp\\ipykernel_7688\\2221469971.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  training_data['c.has_website'] = np.where(training_data['c.website'].isnull(),'No','Yes')\n",
      "C:\\Users\\derek\\AppData\\Local\\Temp\\ipykernel_7688\\2221469971.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  training_data['c.has_contact_detail'] = np.where(training_data['c.email'].isnull() & training_data['c.mobile'].isnull() & training_data['c.landline'].isnull(),'No','Yes')\n",
      "C:\\Users\\derek\\AppData\\Local\\Temp\\ipykernel_7688\\2221469971.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  training_data['c.has_working_hours'] = np.where(training_data['c.hours'].isnull() | training_data['c.hours'] == '\"\"','No','Yes')\n",
      "C:\\Users\\derek\\AppData\\Local\\Temp\\ipykernel_7688\\2221469971.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  training_data['c.in_building'] = np.where(training_data['c.building_name'].isnull(),'No','Yes')\n"
     ]
    }
   ],
   "source": [
    "# Has website, contacts, category, country, wroking hours, in building\n",
    "training_data['c.has_website'] = np.where(training_data['c.website'].isnull(),'No','Yes')\n",
    "training_data['c.has_contact_detail'] = np.where(training_data['c.email'].isnull() & training_data['c.mobile'].isnull() & training_data['c.landline'].isnull(),'No','Yes')\n",
    "training_data['c.has_working_hours'] = np.where(training_data['c.hours'].isnull() | training_data['c.hours'] == '\"\"','No','Yes')\n",
    "training_data['c.in_building'] = np.where(training_data['c.building_name'].isnull(),'No','Yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f40433",
   "metadata": {},
   "source": [
    "**Another important step we can do is engineer a column that will hold the number of non-missing row values for each listing in our database. This is based on our assumption that listings with more complete profiles have a higher probability of being alive.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "16034252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of non-missing values in each row\n",
    "training_data = training_data.fillna('')\n",
    "training_data['num_nonmissing'] = training_data.apply(lambda row: sum(row != ''), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4da5364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the empty strings with 0 after creating the num_nonmissing column\n",
    "location = ['c.latitude', 'c.longitude', 'c.has_contact_number', 'c.health_score']\n",
    "training_data[location] = training_data[location].replace('', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f2a06c",
   "metadata": {},
   "source": [
    "# Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3ac593",
   "metadata": {},
   "source": [
    "**In order to perform modelling techniques, we need to encode the categorical variables while standardizing/normalizing the numerical variables.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7cf0c4",
   "metadata": {},
   "source": [
    "Considering that our data may have outliers when it comes to latitude and longitude, we will resort to using standardization for the numerical features since this preprocessing technique is not affected by outliers in our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "64e3646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate categorical and numerical features\n",
    "cat_cols = ['c.country', 'c.category_list', 'c.website_status', 'c.isp_provider', 'c.data_source', 'c.has_working_hours', 'c.in_building', 'c.has_website', 'c.has_contact_detail']\n",
    "num_cols = ['c.latitude', 'c.longitude', 'c.health_score']\n",
    "\n",
    "# Label encode categorical features\n",
    "for col in cat_cols:\n",
    "    training_data[col] = training_data[col].astype('category')\n",
    "    training_data[col] = training_data[col].cat.codes\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "training_data[num_cols] = scaler.fit_transform(training_data[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "61dfd371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before fitting our Kmeans cluster algorithm, we can drop the unnecessary variables in our dataset\n",
    "training_data.drop(['c.company_name_en','c.email','c.mobile','c.landline','c.website','c.building_name','c.hours','c.confidence_indicator'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "124d10c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c.country</th>\n",
       "      <th>c.category_list</th>\n",
       "      <th>c.isp_provider</th>\n",
       "      <th>c.has_contact_number</th>\n",
       "      <th>c.health_score</th>\n",
       "      <th>c.website_status</th>\n",
       "      <th>c.data_source</th>\n",
       "      <th>c.latitude</th>\n",
       "      <th>c.longitude</th>\n",
       "      <th>c.is_verified</th>\n",
       "      <th>c.has_website</th>\n",
       "      <th>c.has_contact_detail</th>\n",
       "      <th>c.has_working_hours</th>\n",
       "      <th>c.in_building</th>\n",
       "      <th>num_nonmissing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.031193</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>0.196873</td>\n",
       "      <td>-0.539684</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>1136</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.031193</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196873</td>\n",
       "      <td>-0.539684</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>5511</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.031193</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.097785</td>\n",
       "      <td>1.552553</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>293</td>\n",
       "      <td>114</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986903</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>-2.096542</td>\n",
       "      <td>1.551491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.031193</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.196873</td>\n",
       "      <td>-0.539684</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c.country  c.category_list  c.isp_provider  c.has_contact_number  \\\n",
       "0          0                0               0                   0.0   \n",
       "1         13             1136              27                   1.0   \n",
       "2         40             5511               0                   0.0   \n",
       "3         40              293             114                   1.0   \n",
       "4          0                0              27                   1.0   \n",
       "\n",
       "   c.health_score  c.website_status  c.data_source  c.latitude  c.longitude  \\\n",
       "0       -0.031193                 0            109    0.196873    -0.539684   \n",
       "1       -0.031193                 0              0    0.196873    -0.539684   \n",
       "2       -0.031193                 2              0   -2.097785     1.552553   \n",
       "3        0.986903                 0             45   -2.096542     1.551491   \n",
       "4       -0.031193                 0             53    0.196873    -0.539684   \n",
       "\n",
       "   c.is_verified  c.has_website  c.has_contact_detail  c.has_working_hours  \\\n",
       "0              1              0                     0                    0   \n",
       "1              0              0                     1                    0   \n",
       "2              0              1                     0                    0   \n",
       "3              0              0                     1                    0   \n",
       "4              0              0                     1                    0   \n",
       "\n",
       "   c.in_building  num_nonmissing  \n",
       "0              0               8  \n",
       "1              0              13  \n",
       "2              0              13  \n",
       "3              0              16  \n",
       "4              0              11  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview of the data after encoding and dropping unnecessary features.\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10583794",
   "metadata": {},
   "source": [
    "Considering the distribution of data is uneven in our dataset, we will randomize our train dataset before splitting into a 70-30 split for modelling purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3b3968ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(880167, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c.country</th>\n",
       "      <th>c.category_list</th>\n",
       "      <th>c.isp_provider</th>\n",
       "      <th>c.has_contact_number</th>\n",
       "      <th>c.health_score</th>\n",
       "      <th>c.website_status</th>\n",
       "      <th>c.data_source</th>\n",
       "      <th>c.latitude</th>\n",
       "      <th>c.longitude</th>\n",
       "      <th>c.is_verified</th>\n",
       "      <th>c.has_website</th>\n",
       "      <th>c.has_contact_detail</th>\n",
       "      <th>c.has_working_hours</th>\n",
       "      <th>c.in_building</th>\n",
       "      <th>num_nonmissing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189874</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.031193</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.196873</td>\n",
       "      <td>-0.539684</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579881</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.031193</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.973290</td>\n",
       "      <td>1.878943</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.031193</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.196873</td>\n",
       "      <td>-0.539684</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610842</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.031193</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.196873</td>\n",
       "      <td>-0.539684</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87059</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.031193</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.196873</td>\n",
       "      <td>-0.539684</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        c.country  c.category_list  c.isp_provider  c.has_contact_number  \\\n",
       "189874          0                0              27                   1.0   \n",
       "579881         30                0               0                   0.0   \n",
       "191             0                0              27                   1.0   \n",
       "610842          0                0              27                   1.0   \n",
       "87059           0                0              27                   1.0   \n",
       "\n",
       "        c.health_score  c.website_status  c.data_source  c.latitude  \\\n",
       "189874       -0.031193                 0             38    0.196873   \n",
       "579881       -0.031193                 0              0   -1.973290   \n",
       "191          -0.031193                 0             53    0.196873   \n",
       "610842       -0.031193                 0             53    0.196873   \n",
       "87059        -0.031193                 0             38    0.196873   \n",
       "\n",
       "        c.longitude  c.is_verified  c.has_website  c.has_contact_detail  \\\n",
       "189874    -0.539684              0              0                     1   \n",
       "579881     1.878943              0              0                     0   \n",
       "191       -0.539684              0              0                     1   \n",
       "610842    -0.539684              0              0                     1   \n",
       "87059     -0.539684              0              0                     1   \n",
       "\n",
       "        c.has_working_hours  c.in_building  num_nonmissing  \n",
       "189874                    0              0              11  \n",
       "579881                    0              0              12  \n",
       "191                       0              0              11  \n",
       "610842                    0              0              11  \n",
       "87059                     0              0              11  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomize the dataset before splitting into train and test\n",
    "trains = training_data.sample(frac=1)\n",
    "print(trains.shape)\n",
    "trains.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "33ff4471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split (70:30 split)\n",
    "trains_data = trains.iloc[0:616001] # Train set\n",
    "test_data = trains.iloc[616001:880168] # Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd91c13",
   "metadata": {},
   "source": [
    "## Initialize the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb5d2c7",
   "metadata": {},
   "source": [
    "Considering we want the confidence score to range between 0 and 1, we can initialize the Kmeans algorithm with 10 clusters then we'll later optimize with the best parameters using GridSearchCV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "89c66d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(max_iter=100, n_clusters=3, random_state=42)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform clustering on the train set data\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, max_iter=100)\n",
    "kmeans.fit(trains_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30060f4a",
   "metadata": {},
   "source": [
    "* In this stage, we will get the cluster labels for each data point before calculating the confidence score. \n",
    "\n",
    "* We will then calculate the confidence score as a fraction of the non-missing values in each cluster and assign the value to each listing in the cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "484a3a86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the cluster labels for each data point\n",
    "cluster_labels = kmeans.predict(trains_data)\n",
    "\n",
    "# Calculate the confidence score as the fraction of non-missing values in each cluster\n",
    "num_nonmissing_means = []\n",
    "for cluster in range(kmeans.n_clusters):\n",
    "    mask = (cluster_labels == cluster)\n",
    "    cluster_df = trains_data[mask]\n",
    "    num_nonmissing_mean = cluster_df['num_nonmissing'].mean()\n",
    "    num_nonmissing_means.append(num_nonmissing_mean)\n",
    "\n",
    "confidence_scores = []\n",
    "for label in cluster_labels:\n",
    "    confidence_scores.append(num_nonmissing_means[label] / len(trains_data.columns))\n",
    "\n",
    "print(confidence_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ccfcdf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76852253 0.91913835 0.89198431]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\derek\\AppData\\Local\\Temp\\ipykernel_7688\\1892472745.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  trains_data['confidence_score'] = confidence_scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c.country</th>\n",
       "      <th>c.category_list</th>\n",
       "      <th>c.isp_provider</th>\n",
       "      <th>c.has_contact_number</th>\n",
       "      <th>c.health_score</th>\n",
       "      <th>c.website_status</th>\n",
       "      <th>c.data_source</th>\n",
       "      <th>c.latitude</th>\n",
       "      <th>c.longitude</th>\n",
       "      <th>c.is_verified</th>\n",
       "      <th>c.has_website</th>\n",
       "      <th>c.has_contact_detail</th>\n",
       "      <th>c.has_working_hours</th>\n",
       "      <th>c.in_building</th>\n",
       "      <th>num_nonmissing</th>\n",
       "      <th>confidence_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189874</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.031193</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.196873</td>\n",
       "      <td>-0.539684</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.768523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579881</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.031193</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.973290</td>\n",
       "      <td>1.878943</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.768523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.031193</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.196873</td>\n",
       "      <td>-0.539684</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.768523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610842</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.031193</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.196873</td>\n",
       "      <td>-0.539684</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.768523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87059</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.031193</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.196873</td>\n",
       "      <td>-0.539684</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.768523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        c.country  c.category_list  c.isp_provider  c.has_contact_number  \\\n",
       "189874          0                0              27                   1.0   \n",
       "579881         30                0               0                   0.0   \n",
       "191             0                0              27                   1.0   \n",
       "610842          0                0              27                   1.0   \n",
       "87059           0                0              27                   1.0   \n",
       "\n",
       "        c.health_score  c.website_status  c.data_source  c.latitude  \\\n",
       "189874       -0.031193                 0             38    0.196873   \n",
       "579881       -0.031193                 0              0   -1.973290   \n",
       "191          -0.031193                 0             53    0.196873   \n",
       "610842       -0.031193                 0             53    0.196873   \n",
       "87059        -0.031193                 0             38    0.196873   \n",
       "\n",
       "        c.longitude  c.is_verified  c.has_website  c.has_contact_detail  \\\n",
       "189874    -0.539684              0              0                     1   \n",
       "579881     1.878943              0              0                     0   \n",
       "191       -0.539684              0              0                     1   \n",
       "610842    -0.539684              0              0                     1   \n",
       "87059     -0.539684              0              0                     1   \n",
       "\n",
       "        c.has_working_hours  c.in_building  num_nonmissing  confidence_score  \n",
       "189874                    0              0              11          0.768523  \n",
       "579881                    0              0              12          0.768523  \n",
       "191                       0              0              11          0.768523  \n",
       "610842                    0              0              11          0.768523  \n",
       "87059                     0              0              11          0.768523  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a confidence score column that will hold the scores for each listing in our dataset\n",
    "trains_data['confidence_score'] = confidence_scores\n",
    "print(trains_data['confidence_score'].unique())\n",
    "print()\n",
    "trains_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bb9be9",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886415c4",
   "metadata": {},
   "source": [
    "**For hyperparameter tuning, we're basically searching for the best parameters that will give us the best distinction between clusters. In this case we're going to use GridSearchCV.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9040e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_clusters': [3, 5, 7, 10, 15, 20],\n",
    "    'init': ['k-means++', 'random'],\n",
    "    'max_iter': [100, 300, 500],\n",
    "    'tol': [1e-4, 1e-5, 1e-6]\n",
    "}\n",
    "\n",
    "# Create KMeans model\n",
    "kmeans = KMeans()\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(kmeans, param_grid, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(trains_data)\n",
    "\n",
    "# Print best parameters\n",
    "print('Best parameters:', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1684bbaa",
   "metadata": {},
   "source": [
    "After doing some hyperparameter tuning, it was determined that 3 is the optimum number of clusters that we should use for our data. This will be implemented on our test data and evaluated using the silhouette score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352b1105",
   "metadata": {},
   "source": [
    "**Predicting the confidence score of the test dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2e9d11ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicting on a test set\n",
    "# test_data[num_cols] = scaler.transform(test_data[num_cols])\n",
    "predicted_cluster_labels = kmeans.predict(test_data)\n",
    "\n",
    "# Calculate the confidence score as a fraction of non-missing values in each cluster\n",
    "num_nonmissing_means = []\n",
    "for cluster in range(kmeans.n_clusters):\n",
    "    mask = (predicted_cluster_labels == cluster)\n",
    "    cluster_df = test_data[mask]\n",
    "    num_nonmissing_mean = cluster_df['num_nonmissing'].mean()\n",
    "    num_nonmissing_means.append(num_nonmissing_mean)\n",
    "\n",
    "test_confidence_scores = []\n",
    "for label in predicted_cluster_labels:\n",
    "    test_confidence_scores.append(num_nonmissing_means[label] / len(test_data.columns))\n",
    "\n",
    "print(test_confidence_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "11fbce58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76921841 0.91984279 0.89174415]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\derek\\AppData\\Local\\Temp\\ipykernel_7688\\2115312431.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['confidence_score'] = test_confidence_scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c.country</th>\n",
       "      <th>c.category_list</th>\n",
       "      <th>c.isp_provider</th>\n",
       "      <th>c.has_contact_number</th>\n",
       "      <th>c.health_score</th>\n",
       "      <th>c.website_status</th>\n",
       "      <th>c.data_source</th>\n",
       "      <th>c.latitude</th>\n",
       "      <th>c.longitude</th>\n",
       "      <th>c.is_verified</th>\n",
       "      <th>c.has_website</th>\n",
       "      <th>c.has_contact_detail</th>\n",
       "      <th>c.has_working_hours</th>\n",
       "      <th>c.in_building</th>\n",
       "      <th>num_nonmissing</th>\n",
       "      <th>confidence_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>813292</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.031193</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.196873</td>\n",
       "      <td>-0.539684</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.769218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339324</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986903</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769772</td>\n",
       "      <td>-0.286691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.769218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199111</th>\n",
       "      <td>22</td>\n",
       "      <td>2934</td>\n",
       "      <td>77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986903</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.196873</td>\n",
       "      <td>-0.539684</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.919843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641462</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.049289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196873</td>\n",
       "      <td>-0.539684</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.769218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17357</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.031193</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.196873</td>\n",
       "      <td>-0.539684</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.769218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        c.country  c.category_list  c.isp_provider  c.has_contact_number  \\\n",
       "813292          0                0              27                   1.0   \n",
       "339324         33                0              54                   1.0   \n",
       "199111         22             2934              77                   1.0   \n",
       "641462         33                0               0                   0.0   \n",
       "17357           0                0              27                   1.0   \n",
       "\n",
       "        c.health_score  c.website_status  c.data_source  c.latitude  \\\n",
       "813292       -0.031193                 0             53    0.196873   \n",
       "339324        0.986903                 0              0    0.769772   \n",
       "199111        0.986903                 1             45    0.196873   \n",
       "641462       -1.049289                 0              0    0.196873   \n",
       "17357        -0.031193                 0             53    0.196873   \n",
       "\n",
       "        c.longitude  c.is_verified  c.has_website  c.has_contact_detail  \\\n",
       "813292    -0.539684              0              0                     1   \n",
       "339324    -0.286691              0              0                     1   \n",
       "199111    -0.539684              0              1                     1   \n",
       "641462    -0.539684              0              0                     0   \n",
       "17357     -0.539684              0              0                     1   \n",
       "\n",
       "        c.has_working_hours  c.in_building  num_nonmissing  confidence_score  \n",
       "813292                    0              0              11          0.769218  \n",
       "339324                    0              0              15          0.769218  \n",
       "199111                    0              0              15          0.919843  \n",
       "641462                    0              0              10          0.769218  \n",
       "17357                     0              0              11          0.769218  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a confidence score column\n",
    "test_data['confidence_score'] = test_confidence_scores\n",
    "print(test_data['confidence_score'].unique())\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15e75d6",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5703bf7a",
   "metadata": {},
   "source": [
    "**We'll be using the silhouette score to evaluate the consistency within clusters of data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "93a905ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score:  0.7973394193735287\n"
     ]
    }
   ],
   "source": [
    "# Compute the silhouette score\n",
    "from sklearn.metrics import silhouette_score\n",
    "silhouette = silhouette_score(test_data, predicted_cluster_labels)\n",
    "\n",
    "print(\"Silhouette score: \", silhouette)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fc2745",
   "metadata": {},
   "source": [
    "# Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f76bd18",
   "metadata": {},
   "source": [
    "1. When using **10 clusters** in our Kmeans cluster algorithm, our **silhouette score was 0.74** which is pretty accurate. \n",
    "\n",
    "\n",
    "2. When using **3 clusters**, the **silhouette score improved to 0.8** which is much more accurate than when using 10 clusters. \n",
    "\n",
    "\n",
    "3. For new listings, we will use 3 clusters as a parameter in our kMeans algorithm so as to get the best distinction between listings in our database. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
